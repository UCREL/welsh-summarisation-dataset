{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "welsh_summariser.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "9iEeBseYxDIN",
        "tMSFfg5Y7E5W",
        "syp0ZETUaPoq"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNe3+OWR/+s+CiOfATXxjlw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnatiusEzeani/welsh-text-summarizer/blob/main/welsh_summariser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn41SqGn74Q7"
      },
      "source": [
        "## Setting up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72-zM95yvxg0"
      },
      "source": [
        "### a. Installing and importing required Python libraries\n",
        "To do later:\n",
        "1.   Mount the GDrive\n",
        "2.   Clone the repo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CoabX_QBNuqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEGPLTpuQHJU"
      },
      "source": [
        "## install dependencies\n",
        "def setup(dependencies):\n",
        " # create the requirement file with the dependencies\n",
        "  with open(\"requirements.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(dependencies))\n",
        "  !pip install -r requirements.txt\n",
        "  def install_java():\n",
        "    !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"   #set environment variable\n",
        "    !java -version       #check java version\n",
        "\n",
        "setup(dependencies = [\"rouge\", \"rouge-metric\", \"lexrank\", \"summa\", \"fasttext\"])\n",
        "\n",
        "# load setup.py\n",
        "!wget https://raw.githubusercontent.com/IgnatiusEzeani/summariser/master/setup.py\n",
        "\n",
        "# load rouge 2.0 eval jar file\n",
        "!wget https://github.com/IgnatiusEzeani/summariser/raw/master/rouge2-1.2.2.jar\n",
        "!wget https://raw.githubusercontent.com/IgnatiusEzeani/summariser/master/rouge.properties\n",
        "\n",
        "%run setup.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iEeBseYxDIN"
      },
      "source": [
        "## Get Articles and Summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rahWSemxXEm"
      },
      "source": [
        "### a. Extract Wiki articles and summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiXFYTp2Z4d3"
      },
      "source": [
        "# Extract articles and summaries\n",
        "data_file = \"welsh_wiki_articles.json\"\n",
        "if not os.path.exists(data_file):\n",
        "  # Download and unzip data.zip\n",
        "  !wget https://github.com/IgnatiusEzeani/summariser/raw/master/data.zip\n",
        "  unzip(\"data.zip\")\n",
        "\n",
        "  folder_path = \"data/html\"\n",
        "  welsh_wiki_articles={}\n",
        "  for fname in os.listdir(folder_path):\n",
        "      filepath = os.path.join(folder_path, fname)\n",
        "      html = open(filepath, \"r\", encoding=\"utf8\").read()\n",
        "      soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "      text = soup.get_text()\n",
        "      #extract row 'fileId', 'title', 'article' and 'summary'\n",
        "      fileId = getfileID(fname)\n",
        "      headings = ['title', 'text', 'summary']\n",
        "      title, article, summary = [\n",
        "        extract_text(text, f\"begin {item}\", f\"end {item}\") for item in headings]\n",
        "      welsh_wiki_articles[fileId] = {\"fileId\":f\"'{fileId}'\", \"title\":title,\n",
        "                                     \"article\":article, \"summary\":summary}\n",
        "  # Store in a json file for future use\n",
        "  welsh_wiki_articles_json_dump = json.dumps(welsh_wiki_articles)\n",
        "  with open(data_file, \"w\", encoding = \"ISO-8859-1\") as jsonfile:\n",
        "    jsonfile.write(welsh_wiki_articles_json_dump)\n",
        "    print(f\"{data_file} created!\")\n",
        "  \n",
        "  # Remove the data folder\n",
        "  shutil.rmtree(\"data\")\n",
        "else:\n",
        "  print(f\"{data_file} already exists\")\n",
        "\n",
        "# Ensure that \"welsh_wiki_articles.json\" is available\n",
        "wiki_articles_summaries_df = \\\n",
        "      pd.io.json.read_json(data_file, orient='index').sort_index()\n",
        "wiki_articles_summaries_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK_kmPQFx3SA"
      },
      "source": [
        "### b. Upload human summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJS6oVZzv9wO"
      },
      "source": [
        "# Upload and extract Wiki articles and summaries\n",
        "# !wget https://raw.githubusercontent.com/IgnatiusEzeani/summariser/master/acc_prelim.csv\n",
        "# human_summaries_prelim_df = pd.read_csv('acc_prelim.csv', encoding=\"ISO-8859-1\")\n",
        "# human_summaries_prelim_df.dropna(subset=['Crynodeb (tua 250 gair)'], inplace=True)\n",
        "# print(len(human_summaries_prelim_df))\n",
        "# human_summaries_prelim_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgWZIF1sayhr"
      },
      "source": [
        "# Upload and extract Wiki articles and summaries\n",
        "# import pandas as pd\n",
        "!wget https://github.com/IgnatiusEzeani/summariser/raw/master/acc_data.csv\n",
        "human_summaries_df = pd.read_csv('acc_data.csv', encoding=\"ISO-8859-1\")\n",
        "human_summaries_df.dropna(subset=['Summary'], inplace=True)\n",
        "# human_summaries_df.dropna(how='all', axis=1, inplace=True)\n",
        "print(len(human_summaries_df))\n",
        "# human_summaries_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMSFfg5Y7E5W"
      },
      "source": [
        "## Run Baseline Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBUhL6fI7V0n"
      },
      "source": [
        "### 1. BottomLine model\n",
        "- This model basically takes the top sentence i.e. the top sentence from each of the Wiki article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LY6Q8HIX34C"
      },
      "source": [
        "bottomline_summaries_df = summarize(wiki_articles_summaries_df, \"bottomline\")\n",
        "# bottomline_summaries_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMOAOSCfH2BB"
      },
      "source": [
        "### 2. LexRank model\n",
        "Uses lexrank (https://pypi.org/project/lexrank/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8WFWmf1Zr78"
      },
      "source": [
        "lexrank_summaries_df = summarize(wiki_articles_summaries_df, \"lexrank\")\n",
        "# lexrank_summaries_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqqWRmMsMTjs"
      },
      "source": [
        "### 3. TextRank model\n",
        "Uses `summa` (https://pypi.org/project/summa/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKkUiPgqatdl"
      },
      "source": [
        "textrank_summaries_df = summarize(wiki_articles_summaries_df, \"textrank\")\n",
        "# textrank_summaries_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYTDrJcqZW_t"
      },
      "source": [
        "## Run Topline Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syp0ZETUaPoq"
      },
      "source": [
        "### 1. TfIdf model\n",
        "Uses `sklearn`'s [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) and [`cosine_similarity`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO5r8iPlY_Hg"
      },
      "source": [
        "tfidf_summaries_df = summarize(wiki_articles_summaries_df,\"tfidf\")\n",
        "tfidf_summaries_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV6IiBQytRZm"
      },
      "source": [
        "### 2. Word Embeddings (FastText)\n",
        "Source [FastText Library for efficient text classification and representation learning](https://fasttext.cc/docs/en/crawl-vectors.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = get_corpus_features(wiki_articles_summaries_df) # default features=100"
      ],
      "metadata": {
        "id": "_r0rPB-DhLOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaKl-KpChm4f"
      },
      "source": [
        "if os.path.exists(\"fastext_feat100_pkl\"):\n",
        "  filtered_fasttext = pickle.load(open('fastext_feat100_pkl', 'rb'))\n",
        "else:\n",
        "  !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.cy.300.bin.gz\n",
        "  unzip('cc.cy.300.bin.gz')\n",
        "  fasttext_model = fasttext.load_model('cc.cy.300.bin')\n",
        "  filtered_fastext = {feature:fasttext_model[feature] for feature in features}\n",
        "\n",
        "  # pickle filtered fasttext for future use\n",
        "  with open('fastext_feat100_pkl', 'wb') as fasttext_pkl:\n",
        "    pickle.dump(filtered_fastext, fasttext_pkl)\n",
        "  !rm 'cc.cy.300.bin'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: modify to use filtered_fastext keys as features later...\n",
        "fasttext_summaries_df = summarize(wiki_articles_summaries_df, \"fasttext\",\n",
        "                                  filtered_fastext) \n",
        "fasttext_summaries_df.head()"
      ],
      "metadata": {
        "id": "JUicW8EkouO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfanEU4V1GQv"
      },
      "source": [
        "### 3. Word Embeddings (WNLT)\n",
        "Source: Pretrained model from [Welsh Natural Language Technology](https://datainnovation.cardiff.ac.uk/is/wecy/access.html) resources."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run setup.py"
      ],
      "metadata": {
        "id": "UzhBW6HVD5ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rYXnqTHQE77"
      },
      "source": [
        "if os.path.exists(\"wnlt_feat100_pkl\"):\n",
        "  filtered_wnlt = pickle.load(open('wnlt_feat100_pkl', 'rb'))\n",
        "else:\n",
        "  # !wget https://datainnovation.cardiff.ac.uk/is/wecy/files/FastText_WNLT_SkipGram.zip\n",
        "  unzip(\"FastText_WNLT_SkipGram.zip\")\n",
        "\n",
        "  # Loading in FastText_WNLT_SkipGram\n",
        "  wnlt_dir = \"./FastText_WNLT_SkipGram/FastText_WNLT_SkipGram\"\n",
        "  wnlt_model = gensim.models.FastText.load(os.path.join(wnlt_dir, 'skipgram_subword_model.model'))\n",
        "\n",
        "  filtered_wnlt = {feature:wnlt_model[feature] for feature in features}\n",
        "\n",
        "  # pickle filtered WNLT for future use\n",
        "  with open('wnlt_feat100_pkl', 'wb') as fasttext_pkl:\n",
        "    pickle.dump(filtered_fastext, fasttext_pkl)\n",
        "\n",
        "  shutil.rmtree('FastText_WNLT_SkipGram')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnlt_summaries_df = summarize(wiki_articles_summaries_df, \"wnlt\", filtered_wnlt)\n",
        "wnlt_summaries_df.head()"
      ],
      "metadata": {
        "id": "VBr1BOXe4dDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGBtXogNczfF"
      },
      "source": [
        "## Run Model Evaluation\n",
        "Uses `rouge-2.0` (https://github.com/kavgan/ROUGE-2.0)\n",
        "\n",
        "### Generating reference and system summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIYCQ_9BNwBq"
      },
      "source": [
        "# # download and unzip system summaries\n",
        "# #Todo: put in a function\n",
        "# !wget https://github.com/IgnatiusEzeani/summariser/raw/master/system_summaries.zip\n",
        "# zip_file = \"system_summaries.zip\"\n",
        "# unzip(zip_file)\n",
        "\n",
        "# system_summaries_dir = os.path.join('.',zip_file[:-4],zip_file[:-4])\n",
        "\n",
        "# summaries_bottomline_df = pd.read_json(os.path.join(system_summaries_dir,\n",
        "#                                       'summaries_bottomline.json'),\n",
        "#                                        orient=\"index\")\n",
        "# summaries_lexrank_df = pd.read_json(os.path.join(system_summaries_dir,\n",
        "#                                       'summaries_lexrank.json'),\n",
        "#                                        orient=\"index\")\n",
        "# summaries_textrank_df = pd.read_json(os.path.join(system_summaries_dir,\n",
        "#                                       'summaries_textrank.json'),\n",
        "#                                        orient=\"index\")\n",
        "# summaries_tfidf_df = pd.read_json(os.path.join(system_summaries_dir,\n",
        "#                                       'summaries_tfidf.json'),\n",
        "#                                        orient=\"index\")\n",
        "# summaries_fasttext_df = pd.read_json(os.path.join(system_summaries_dir,\n",
        "#                                       'summaries_fasttext.json'),\n",
        "#                                        orient=\"index\")\n",
        "# summaries_wnlt_df = pd.read_json(os.path.join(system_summaries_dir,\n",
        "#                                       'summaries_wnlt.json'),\n",
        "#                                        orient=\"index\")\n",
        "summaries_bottomline_df = pd.read_json('summaries_bottomline.json', orient=\"index\")\n",
        "summaries_lexrank_df = pd.read_json('summaries_lexrank.json', orient=\"index\")\n",
        "summaries_textrank_df = pd.read_json('summaries_textrank.json', orient=\"index\")\n",
        "summaries_tfidf_df = pd.read_json('summaries_tfidf.json', orient=\"index\")\n",
        "summaries_fasttext_df = pd.read_json('summaries_fasttext.json', orient=\"index\")\n",
        "summaries_wnlt_df = pd.read_json('summaries_wnlt.json',orient=\"index\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9-k4QpzUm3a"
      },
      "source": [
        "# Generating reference and model summaries for evaluation\n",
        "if os.path.exists('projects'): shutil.rmtree('projects')\n",
        "# reference_types = [(human_summaries_df, \"human\"), (wiki_articles_summaries_df, \"wiki\")]\n",
        "reference_types = [(wiki_articles_summaries_df, \"wiki\")]\n",
        "\n",
        "# Set up models for system summaries\n",
        "models = [(\"bottomline\", summaries_bottomline_df),\n",
        "          (\"lexrank\", summaries_lexrank_df),\n",
        "          (\"textrank\", summaries_textrank_df),\n",
        "          (\"tfidf\", summaries_tfidf_df),\n",
        "          (\"fasttext\", summaries_fasttext_df),\n",
        "          (\"wnlt\", summaries_wnlt_df)\n",
        "          ]\n",
        "# Generate reference summaries\n",
        "gen_reference_summaries(reference_types)\n",
        "\n",
        "# Generate system summaries\n",
        "gen_system_summaries(models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run evaluation of system summaries on system summaries"
      ],
      "metadata": {
        "id": "wLRRHkcjVKLp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssSk8RHexXuL"
      },
      "source": [
        "# run evaluation\n",
        "!java -jar \"rouge2-1.2.2.jar\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for model, scores in model_results.items():\n",
        "#   print(model)\n",
        "#   for scr in scores:\n",
        "#     print(scr)"
      ],
      "metadata": {
        "id": "q5HiabaYaNsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GVoGTAJ1lQm"
      },
      "source": [
        "model_results = get_model_results(show_results('results_wiki_all.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre, rec, f1 = model_results['BOTTOMLINE1.TXT']\n",
        "pre, rec, f1"
      ],
      "metadata": {
        "id": "VSaBb49rIszT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Results Graphs and Barcharts\n",
        "Generate plots of the system output results"
      ],
      "metadata": {
        "id": "mLYf94yiwLqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_types = ['BOTTOMLINE1.TXT', 'TEXTRANK1.TXT', 'LEXRANK1.TXT',\n",
        "                'TFIDF1.TXT', 'FASTTEXT1.TXT', 'WNLT1.TXT']\n",
        "\n",
        "metric_types = ['Rg-1', 'Rg-2', 'Rg-L', 'R-SU4']\n",
        "x_ticks = np.arange(len(metric_types))\n",
        "rows, cols = 2, 3\n",
        "\n",
        "fig, axs = plt.subplots(rows, cols, figsize=(18,10))\n",
        "plt.setp(axs, xticks=x_ticks, xticklabels=metric_types)\n",
        "\n",
        "for i, (r, c) in enumerate(sorted([(i%rows,i%cols) for i in range(len(model_types))])):\n",
        "  axs[r, c].set_title(model_types[i])\n",
        "\n",
        "  pre, rec, f1 = model_results[model_types[i]]\n",
        "\n",
        "  axs[r, c].bar(X_axis - 0.3, pre, 0.3, label = 'Pre')\n",
        "  axs[r, c].bar(X_axis + 0.0, rec, 0.3, label = 'Rec')\n",
        "  axs[r, c].bar(X_axis + 0.3, f1,  0.3, label = 'F1')\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(ylabel='Scores', xlabel='Metrics')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "# for ax in axs.flat:\n",
        "#     ax.label_outer()\n",
        "\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "IzH_LAr1ghDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some example data to display\n",
        "x = np.linspace(0, 2 * np.pi, 400)\n",
        "y = np.sin(x ** 2)\n",
        "\n",
        "fig, axs = plt.subplots(2, 3, figsize=(15,10))\n",
        "axs[0, 0].plot(x, y)\n",
        "axs[0, 0].set_title('Axis [0, 0]')\n",
        "\n",
        "# axs[0, 1].plot(x, y, 'tab:orange')\n",
        "# axs[0, 1].set_title('Axis [0, 1]')\n",
        "# axs[0, 2].plot(x, -y, 'tab:green')\n",
        "# axs[0, 2].set_title('Axis [0, 2]')\n",
        "\n",
        "# axs[1, 0].plot(x, y)\n",
        "# axs[1, 0].set_title('Axis [1, 0]')\n",
        "# axs[1, 1].plot(x, y, 'tab:orange')\n",
        "# axs[1, 1].set_title('Axis [1, 1]')\n",
        "# axs[1, 2].plot(x, -y, 'tab:green')\n",
        "# axs[1, 2].set_title('Axis [1, 2]')\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='x-label', ylabel='y-label')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "id": "sok8It-X8B2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=\"\"\"\n",
        "Models+Metric   Pre        Rec     F-Meas\n",
        "BOTTOMLINE1.TXT:\n",
        " ROUGE-1   &    70.52  &  06.34  &  11.15 \\\\\n",
        " ROUGE-2   &    42.20  &  03.71  &  06.53 \\\\\n",
        " ROUGE-L   &    61.69  &  08.25  &  13.94 \\\\\n",
        " ROUGE-SU4 &    44.62  &  03.77  &  06.65 \\\\\n",
        "TEXTRANK1.TXT:\n",
        " ROUGE-1   &    27.60  &  70.17  &  36.73 \\\\\n",
        " ROUGE-2   &    15.90  &  39.89  &  21.04 \\\\\n",
        " ROUGE-L   &    26.85  &  56.05  &  33.97 \\\\\n",
        " ROUGE-SU4 &    17.36  &  42.82  &  22.83 \\\\ \n",
        "LEXRANK1.TXT:\n",
        " ROUGE-1   &    30.10  &  67.44  &  38.11 \\\\\n",
        " ROUGE-2   &    17.09  &  37.53  &  21.43 \\\\\n",
        " ROUGE-L   &    27.85  &  53.08  &  33.96 \\\\\n",
        " ROUGE-SU4 &    18.78  &  40.42  &  23.38 \\\\\n",
        "\n",
        "TFIDF1.TXT:\n",
        " ROUGE-1   &    29.83  &  67.59  &  37.84 \\\\\n",
        " ROUGE-2   &    17.05  &  37.91  &  21.41 \\\\\n",
        " ROUGE-L   &    28.43  &  52.95  &  34.31 \\\\\n",
        " ROUGE-SU4 &    18.76  &  40.89  &  23.39 \\\\ \n",
        "FASTTEXT1.TXT:\n",
        " ROUGE-1   &    29.37  &  68.68  &  37.75 \\\\\n",
        " ROUGE-2   &    16.72  &  38.52  &  21.35 \\\\\n",
        " ROUGE-L   &    27.74  &  55.11  &  34.35 \\\\\n",
        " ROUGE-SU4 &    18.37  &  41.48  &  23.27 \\\\\n",
        "WNLT1.TXT:\n",
        " ROUGE-1   &    28.66  &  70.78  &  37.50 \\\\\n",
        " ROUGE-2   &    16.48  &  40.04  &  21.37 \\\\\n",
        " ROUGE-L   &    27.24  &  57.13  &  34.35 \\\\\n",
        " ROUGE-SU4 &    17.99  &  43.01  &  23.21 \\\\\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "c0jaEbHZK7KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqyFLdKvyVLE"
      },
      "source": [
        "**Human Summaries**\n",
        "```\n",
        "Models+Metric   Pre\t    Rec     F-Meas\n",
        "BOTTOMLINE1.TXT:\n",
        " ROUGE-1   &\t70.52  &  06.34  &  11.15 \\\\\n",
        " ROUGE-2   &\t42.20  &  03.71  &  06.53 \\\\\n",
        " ROUGE-L   &\t61.69  &  08.25  &  13.94 \\\\\n",
        " ROUGE-SU4 &\t44.62  &  03.77  &  06.65 \\\\\n",
        "TEXTRANK1.TXT:\n",
        " ROUGE-1   &\t27.60  &  70.17  &  36.73 \\\\\n",
        " ROUGE-2   &\t15.90  &  39.89  &  21.04 \\\\\n",
        " ROUGE-L   &\t26.85  &  56.05  &  33.97 \\\\\n",
        " ROUGE-SU4 &\t17.36  &  42.82  &  22.83 \\\\ \n",
        "LEXRANK1.TXT:\n",
        " ROUGE-1   &\t30.10  &  67.44  &  38.11 \\\\\n",
        " ROUGE-2   &\t17.09  &  37.53  &  21.43 \\\\\n",
        " ROUGE-L   &\t27.85  &  53.08  &  33.96 \\\\\n",
        " ROUGE-SU4 &\t18.78  &  40.42  &  23.38 \\\\\n",
        " \n",
        "TFIDF1.TXT:\n",
        " ROUGE-1   &\t29.83  &  67.59  &  37.84 \\\\\n",
        " ROUGE-2   &\t17.05  &  37.91  &  21.41 \\\\\n",
        " ROUGE-L   &\t28.43  &  52.95  &  34.31 \\\\\n",
        " ROUGE-SU4 &\t18.76  &  40.89  &  23.39 \\\\ \n",
        "FASTTEXT1.TXT:\n",
        " ROUGE-1   &\t29.37  &  68.68  &  37.75 \\\\\n",
        " ROUGE-2   &\t16.72  &  38.52  &  21.35 \\\\\n",
        " ROUGE-L   &\t27.74  &  55.11  &  34.35 \\\\\n",
        " ROUGE-SU4 &\t18.37  &  41.48  &  23.27 \\\\\n",
        "WNLT1.TXT:\n",
        " ROUGE-1   &\t28.66  &  70.78  &  37.50 \\\\\n",
        " ROUGE-2   &\t16.48  &  40.04  &  21.37 \\\\\n",
        " ROUGE-L   &\t27.24  &  57.13  &  34.35 \\\\\n",
        " ROUGE-SU4 &\t17.99  &  43.01  &  23.21 \\\\\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wiki Summaries**\n",
        "```\n",
        "Models+Metric   Pre\t    Rec     F-Meas\n",
        "BOTTOMLINE1.TXT:\n",
        " ROUGE-1   &\t99.51  &  24.45  &  34.07 \\\\\n",
        " ROUGE-2   &\t99.50  &  23.79  &  33.17 \\\\\n",
        " ROUGE-L   &\t99.53  &  29.03  &  40.26 \\\\\n",
        " ROUGE-SU4 &\t99.48  &  23.11  &  32.23 \\\\\n",
        "TEXTRANK1.TXT:\n",
        " ROUGE-1   &\t21.12  &  81.91  &  29.56 \\\\\n",
        " ROUGE-2   &\t17.98  &  64.62  &  24.61 \\\\\n",
        " ROUGE-L   &\t24.47  &  73.78  &  33.28 \\\\\n",
        " ROUGE-SU4 &\t18.67  &  66.19  &  25.40 \\\\\n",
        "LEXRANK1.TXT:\n",
        " ROUGE-1   &\t22.90  &  79.31  &  30.98 \\\\\n",
        " ROUGE-2   &\t19.04  &  60.95  &  25.07 \\\\\n",
        " ROUGE-L   &\t25.56  &  70.82  &  33.81 \\\\\n",
        " ROUGE-SU4 &\t19.87  &  62.54  &  25.97 \\\\\n",
        "TFIDF1.TXT:\n",
        " ROUGE-1   &\t22.88  &  80.41  &  31.11 \\\\\n",
        " ROUGE-2   &\t19.42  &  63.72  &  25.81 \\\\\n",
        " ROUGE-L   &\t26.44  &  72.38  &  34.93 \\\\\n",
        " ROUGE-SU4 &\t20.21  &  65.16  &  26.66 \\\\\n",
        "FASTTEXT1.TXT:\n",
        " ROUGE-1   &\t22.44  &  80.57  &  30.71 \\\\\n",
        " ROUGE-2   &\t18.87  &  62.82  &  25.20 \\\\\n",
        " ROUGE-L   &\t25.21  &  72.70  &  33.83 \\\\\n",
        " ROUGE-SU4 &\t19.67  &  64.43  &  26.08 \\\\\n",
        "WNLT1.TXT:\n",
        " ROUGE-1   &\t21.73  &  81.80  &  30.19 \\\\\n",
        " ROUGE-2   &\t18.33  &  63.04  &  24.83 \\\\\n",
        " ROUGE-L   &\t24.48  &  73.63  &  33.32 \\\\\n",
        " ROUGE-SU4 &\t19.04  &  64.77  &  25.64 \\\\\n",
        "```"
      ],
      "metadata": {
        "id": "N951_LluZva5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFSqFvwEa1DP"
      },
      "source": [
        "## Playgound"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_tokens = []\n",
        "for i in range(513):\n",
        "  tokens = len(wiki_articles_summaries_df.iloc[i]['article'].split())\n",
        "  article_tokens.append(tokens)\n",
        "  if i % 15 == 0: print()\n",
        "  print(f\"{i:>3d} = {tokens:5d}\", end=\" | \")\n",
        "\n",
        "print(f\"\\n{min(article_tokens)}, {max(article_tokens)}\")"
      ],
      "metadata": {
        "id": "VaqxvlQ0zgO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bins=range(0, 15000, 1000)\n",
        "bin_dict= {i:0 for i in bins}\n",
        "for c in article_tokens:\n",
        "  for rng in bin_dict:\n",
        "    if rng <= c < rng+1000:\n",
        "      bin_dict[rng]+=1\n",
        "      # break\n",
        "print(f\"{bin_dict}, {sum(bin_dict.values())}\")\n",
        "bin_dict = {f\"<{str((k+1000)//1000)}k\":v for k, v in bin_dict.items()}\n",
        "print(bin_dict)"
      ],
      "metadata": {
        "id": "LDAf1JeVIAEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bin_dict = {'<1k': 297, '<2k': 139, '<3k': 31, '<4k': 18, '<5k': 13, '<6k': 7, '>6k': 8}\n",
        "x1 = bin_dict.keys()\n",
        "y1 = bin_dict.values()\n",
        "# fig, ax = plt.subplots(figsize=(10, 5))\n",
        "# fig.subplots_adjust(bottom=0.15, left=0.2)\n",
        "plt.bar(x1, y1)\n",
        "locs, labels = plt.xticks()\n",
        "plt.setp(labels, rotation=90)\n",
        "plt.xlabel('Token count (x 1000)')\n",
        "plt.ylabel('No of Articles')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y6dRban7nNCI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}